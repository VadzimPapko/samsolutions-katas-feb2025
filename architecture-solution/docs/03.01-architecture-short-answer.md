## High-Level Architecture Overview

The system consists of multiple layers to process, analyze, score, and explain candidate responses.

![C1](/architecture-solution//diagrams/C1-ShortAnswers.png)

![General Solution](/architecture-solution/diagrams/ShortAnswersCommon.png)


## 1. Key Components

1.	Preprocessing Layer
	-	Cleans input text (tokenization, lowercasing, stopword removal).
	-	Uses Named Entity Recognition (NER) to identify key domain-specific terms.
2.	BERT Embedding Layer
	-	Converts input text into vector representations.
	-	Uses a fine-tuned BERT model trained on historical expert-graded responses.
3.	Answer Comparison & Similarity Module
	-	Measures semantic similarity between candidate responses and model answers.
	-	Uses Cosine Similarity, Euclidean Distance, or Softmax Scoring.
4.	Rule-Based Scoring Adjustments
	-	Enforces business rules for specific grading requirements.
	-	Adjusts scores for partial correctness based on domain-specific logic.
5.	Feedback & Explanation Generator
	-	Uses Transformer-based interpretability models to explain why an answer was correct/incorrect.
	-	Provides feedback based on knowledge graphs and predefined patterns.
6.	Expert Review Module
	-	Flags low-confidence responses for manual review.
	-	Allows experts to override AI grades & refine training data.
7.	Model Retraining Pipeline
	-	Continuously improves accuracy by incorporating expert feedback.
	-	Uses active learning techniques to retrain BERT on new responses.



## 2. Detailed Breakdown of Components

1. Preprocessing Layer
	-	Tokenization (splitting text into words/tokens).
	-	Stopword removal (removes words like the, is, and).
	-	Lemmatization (reduces words to base form, e.g., running → run).
	-	Named Entity Recognition (NER) for domain-specific terms.

2. BERT Embedding Layer
	-	Fine-tuned BERT model trained on expert-graded responses.
	-	Converts candidate responses into dense vector representations.
	-	Outputs context-aware embeddings for comparison.

3. Answer Comparison & Similarity
	-	Computes similarity score between candidate response & reference answer.
	-	Uses Cosine Similarity to measure closeness.
	-	If similarity score ≥ threshold (e.g., 80%), response is considered correct.

4. Rule-Based Scoring Adjustments
	-	Applies domain-specific rules (e.g., exact term matching for key concepts).
	-	Assigns partial credit if some parts of the answer are correct.

5. Feedback & Explanation Generator
	-	Uses transformer-based techniques to generate explanations.
	-	Maps responses to predefined knowledge graphs for context-aware feedback.

6. Expert Review Module
	-	Flags answers with low confidence scores for manual review.
	-	Stores expert corrections for continuous model improvement.

7. Model Retraining Pipeline
	-	Collects expert-reviewed responses for active learning.
	-	Retrains BERT periodically to improve accuracy over time.

8. Results API
	-	Stores:
	-	Candidate’s final score.
	-	AI-generated feedback.
	-	Expert review status (if applicable).